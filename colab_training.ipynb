{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"},
  "accelerator": "GPU",
  "colab": {"gpuType": "T4", "provenance": []}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›£ï¸ AI Road Quality Monitoring â€” YOLOv8 Training on Google Colab\n",
    "\n",
    "**Runtime â†’ Change runtime type â†’ T4 GPU (FREE)**\n",
    "\n",
    "This notebook trains YOLOv8 on your road damage dataset and downloads the best weights.\n",
    "\n",
    "---\n",
    "**Steps:**\n",
    "1. Check GPU\n",
    "2. Install dependencies\n",
    "3. Download dataset from Roboflow\n",
    "4. Train YOLOv8m\n",
    "5. Evaluate (mAP, confusion matrix)\n",
    "6. Download `best.pt` â†’ use in your local dashboard"
   ],
   "id": "intro"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 1: Check GPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f'\\nPyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ],
   "id": "check_gpu"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 2: Install YOLOv8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install ultralytics roboflow -q\n",
    "from ultralytics import YOLO\n",
    "print('âœ… ultralytics installed')"
   ],
   "id": "install"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 3: Download Dataset from Roboflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Get your FREE API key at https://roboflow.com â†’ Settings â†’ API Keys\n",
    "# Then replace YOUR_API_KEY_HERE below\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "API_KEY = 'YOUR_API_KEY_HERE'   # <â”€â”€â”€ PASTE YOUR KEY HERE\n",
    "\n",
    "rf      = Roboflow(api_key=API_KEY)\n",
    "\n",
    "# Option A: Pothole detection dataset (public, no account needed for download)\n",
    "project = rf.workspace('university-sbxzs').project('pothole-detection-a73yl')\n",
    "version = project.version(1)\n",
    "dataset = version.download('yolov8')\n",
    "\n",
    "print(f'\\nâœ… Dataset downloaded to: {dataset.location}')\n",
    "print(f'   Classes: {dataset.classes}')\n",
    "DATASET_YAML = dataset.location + '/data.yaml'\n",
    "print(f'   Config:  {DATASET_YAML}')"
   ],
   "id": "download_dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 3B (ALTERNATIVE): Use RDD2022 or custom dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# If you uploaded your own dataset to Colab, set the path here:\n",
    "#\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()        # upload your dataset zip\n",
    "# !unzip dataset.zip -d /content/dataset\n",
    "#\n",
    "# DATASET_YAML = '/content/dataset/data.yaml'\n",
    "\n",
    "# Or mount Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DATASET_YAML = '/content/drive/MyDrive/road_dataset/data.yaml'\n",
    "print('Use Cell 3 (Roboflow) or uncomment one of the alternatives above.')"
   ],
   "id": "alt_dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 4: Train YOLOv8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Expected training time on T4 GPU:\n",
    "#   yolov8n  ~20 min for 100 epochs\n",
    "#   yolov8m  ~60 min for 100 epochs  â† recommended\n",
    "#   yolov8l  ~120 min for 100 epochs\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained model (auto-downloads ~50MB weights)\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# â”€â”€ Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results = model.train(\n",
    "    data       = DATASET_YAML,\n",
    "    epochs     = 100,\n",
    "    imgsz      = 640,\n",
    "    batch      = 32,          # T4 has 16GB VRAM, batch=32 is fine\n",
    "    device     = 0,           # GPU 0\n",
    "    patience   = 20,          # Early stopping\n",
    "    optimizer  = 'AdamW',\n",
    "    lr0        = 0.001,\n",
    "    # Augmentation\n",
    "    mosaic     = 1.0,\n",
    "    fliplr     = 0.5,\n",
    "    degrees    = 5.0,\n",
    "    hsv_v      = 0.4,\n",
    "    # Output\n",
    "    project    = '/content/runs',\n",
    "    name       = 'road_damage',\n",
    "    plots      = True,\n",
    "    save       = True,\n",
    "    verbose    = True,\n",
    ")\n",
    "\n",
    "print(f'\\nâœ… Training complete!')\n",
    "print(f'   Best mAP50: {results.results_dict.get(\"metrics/mAP50(B)\", 0):.4f}')\n",
    "print(f'   Results:    {results.save_dir}')"
   ],
   "id": "train"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 5: View Training Plots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "run_dir = Path(results.save_dir)\n",
    "\n",
    "print('=== Training Results ===')\n",
    "display(Image(str(run_dir / 'results.png'), width=900))\n",
    "\n",
    "print('\\n=== Confusion Matrix ===')\n",
    "display(Image(str(run_dir / 'confusion_matrix.png'), width=700))\n",
    "\n",
    "print('\\n=== Precision-Recall Curve ===')\n",
    "display(Image(str(run_dir / 'PR_curve.png'), width=700))"
   ],
   "id": "view_plots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 6: Evaluate on Test Set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "best_model = YOLO(str(run_dir / 'weights' / 'best.pt'))\n",
    "\n",
    "metrics = best_model.val(\n",
    "    data   = DATASET_YAML,\n",
    "    split  = 'test',\n",
    "    imgsz  = 640,\n",
    "    conf   = 0.25,\n",
    "    iou    = 0.50,\n",
    "    plots  = True,\n",
    "    verbose= True,\n",
    ")\n",
    "\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'  TEST SET RESULTS')\n",
    "print(f'{\"=\"*50}')\n",
    "print(f'  mAP50:     {metrics.box.map50:.4f}')\n",
    "print(f'  mAP50-95:  {metrics.box.map:.4f}')\n",
    "print(f'  Precision: {metrics.box.mp:.4f}')\n",
    "print(f'  Recall:    {metrics.box.mr:.4f}')\n",
    "f1 = 2 * metrics.box.mp * metrics.box.mr / (metrics.box.mp + metrics.box.mr + 1e-10)\n",
    "print(f'  F1 Score:  {f1:.4f}')"
   ],
   "id": "evaluate"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 7: Run Inference on Sample Images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import cv2\n",
    "from IPython.display import Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Run on a few test images\n",
    "test_imgs = list((Path(DATASET_YAML).parent / 'test' / 'images').glob('*.jpg'))[:4]\n",
    "\n",
    "if test_imgs:\n",
    "    results_list = best_model.predict(\n",
    "        source = [str(p) for p in test_imgs],\n",
    "        conf   = 0.40,\n",
    "        save   = True,\n",
    "        project= '/content/predictions',\n",
    "        name   = 'test_samples',\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, min(4, len(test_imgs)), figsize=(20, 5))\n",
    "    if len(test_imgs) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, result in zip(axes, results_list):\n",
    "        annotated = result.plot()\n",
    "        ax.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "        n_dets = len(result.boxes) if result.boxes else 0\n",
    "        ax.set_title(f'{n_dets} detections', fontsize=10)\n",
    "\n",
    "    plt.suptitle('YOLOv8 Road Damage Detection â€” Sample Predictions', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No test images found. Check dataset path.')"
   ],
   "id": "inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 8: Benchmark Inference Speed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Warm up\n",
    "for _ in range(5):\n",
    "    best_model.predict(dummy_img, verbose=False)\n",
    "\n",
    "# Benchmark\n",
    "N     = 100\n",
    "times = []\n",
    "for _ in range(N):\n",
    "    t0 = time.perf_counter()\n",
    "    best_model.predict(dummy_img, verbose=False)\n",
    "    times.append(time.perf_counter() - t0)\n",
    "\n",
    "avg_ms = np.mean(times)  * 1000\n",
    "fps    = 1 / np.mean(times)\n",
    "print(f'Average inference: {avg_ms:.1f} ms | FPS: {fps:.1f}')\n",
    "print(f'Real-time capable: {\"YES\" if fps > 25 else \"NO â€” try yolov8n or yolov8s\"}')"
   ],
   "id": "benchmark"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 9: Export to ONNX (for PC deployment) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('Exporting to ONNX format...')\n",
    "exported = best_model.export(\n",
    "    format   = 'onnx',\n",
    "    imgsz    = 640,\n",
    "    simplify = True,\n",
    "    optimize = True,\n",
    ")\n",
    "print(f'âœ… ONNX model: {exported}')"
   ],
   "id": "export"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CELL 10: Download weights to your PC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This downloads best.pt (PyTorch) to your local machine\n",
    "\n",
    "from google.colab import files\n",
    "import shutil, os\n",
    "\n",
    "best_pt   = str(run_dir / 'weights' / 'best.pt')\n",
    "onnx_file = str(run_dir / 'weights' / 'best.onnx')\n",
    "\n",
    "# Bundle weights + results into a zip\n",
    "zip_name = 'road_damage_model.zip'\n",
    "shutil.make_archive(\n",
    "    '/content/road_damage_model', 'zip',\n",
    "    str(run_dir / 'weights')\n",
    ")\n",
    "\n",
    "print('Downloading model weights...')\n",
    "print('After download, put best.pt in: road_quality_monitor/weights/best.pt')\n",
    "files.download('/content/road_damage_model.zip')\n",
    "\n",
    "# Also download training results\n",
    "shutil.copy(str(run_dir / 'results.png'), '/content/training_results.png')\n",
    "files.download('/content/training_results.png')\n",
    "\n",
    "print('\\nâœ… Download complete!')\n",
    "print('   1. Extract road_damage_model.zip')\n",
    "print('   2. Copy best.pt to road_quality_monitor/weights/best.pt')\n",
    "print('   3. Run: streamlit run 4_dashboard/app.py')"
   ],
   "id": "download"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Summary of Expected Results\n",
    "\n",
    "| Metric | Expected Range | Target |\n",
    "|--------|---------------|--------|\n",
    "| mAP50 | 0.65 â€“ 0.85 | > 0.75 |\n",
    "| Precision | 0.70 â€“ 0.90 | > 0.80 |\n",
    "| Recall | 0.60 â€“ 0.80 | > 0.70 |\n",
    "| F1 Score | 0.65 â€“ 0.85 | > 0.75 |\n",
    "| FPS (T4 GPU) | 60â€“120 | > 25 |\n",
    "\n",
    "## ğŸ”§ If mAP is below 0.70\n",
    "1. Add more training images (aim for 500+ per class)\n",
    "2. Check annotations for accuracy\n",
    "3. Train for more epochs (`epochs=150`)\n",
    "4. Try `yolov8l.pt` (larger model)\n",
    "5. Use `model.tune()` for automatic hyperparameter search"
   ],
   "id": "summary"
  }
 ]
}
